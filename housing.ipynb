{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import boston_housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_data, train_targets), (test_data, test_targets) = boston_housing.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404, 13)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(102, 13)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(102,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.23247,   0.     ,   8.14   ,   0.     ,   0.538  ,   6.142  ,\n",
       "        91.7    ,   3.9769 ,   4.     , 307.     ,  21.     , 396.9    ,\n",
       "        18.72   ])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_targets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = train_data.mean()\n",
    "train_data -= mean\n",
    "\n",
    "std = train_data.std(axis=0)\n",
    "train_data /= std\n",
    "\n",
    "test_data -= mean\n",
    "test_data /= std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model() :\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(64, activation='relu', input_shape=(train_data.shape[1],)))\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(1))\n",
    "    model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=5, shuffle=True, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\rajar\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/30\n",
      "323/323 [==============================] - 2s 8ms/step - loss: 262.5168 - mae: 13.4058\n",
      "Epoch 2/30\n",
      "323/323 [==============================] - 0s 260us/step - loss: 1662.1604 - mae: 39.7369\n",
      "Epoch 3/30\n",
      "323/323 [==============================] - 0s 198us/step - loss: 182.0830 - mae: 10.3295\n",
      "Epoch 4/30\n",
      "323/323 [==============================] - 0s 198us/step - loss: 90.9531 - mae: 7.7172\n",
      "Epoch 5/30\n",
      "323/323 [==============================] - 0s 195us/step - loss: 84.1264 - mae: 6.4818\n",
      "Epoch 6/30\n",
      "323/323 [==============================] - 0s 266us/step - loss: 83.3782 - mae: 6.7281\n",
      "Epoch 7/30\n",
      "323/323 [==============================] - 0s 297us/step - loss: 83.2173 - mae: 6.5912\n",
      "Epoch 8/30\n",
      "323/323 [==============================] - 0s 180us/step - loss: 83.1389 - mae: 6.6499\n",
      "Epoch 9/30\n",
      "323/323 [==============================] - 0s 213us/step - loss: 83.0757 - mae: 6.6097\n",
      "Epoch 10/30\n",
      "323/323 [==============================] - 0s 285us/step - loss: 83.0156 - mae: 6.6314\n",
      "Epoch 11/30\n",
      "323/323 [==============================] - 0s 198us/step - loss: 82.9558 - mae: 6.6090\n",
      "Epoch 12/30\n",
      "323/323 [==============================] - 0s 226us/step - loss: 82.8952 - mae: 6.6227\n",
      "Epoch 13/30\n",
      "323/323 [==============================] - 0s 237us/step - loss: 82.8335 - mae: 6.6030\n",
      "Epoch 14/30\n",
      "323/323 [==============================] - 0s 238us/step - loss: 82.7707 - mae: 6.6177\n",
      "Epoch 15/30\n",
      "323/323 [==============================] - 0s 158us/step - loss: 82.7067 - mae: 6.5926\n",
      "Epoch 16/30\n",
      "323/323 [==============================] - 0s 155us/step - loss: 82.6424 - mae: 6.6182\n",
      "Epoch 17/30\n",
      "323/323 [==============================] - 0s 220us/step - loss: 82.5804 - mae: 6.5725\n",
      "Epoch 18/30\n",
      "323/323 [==============================] - 0s 220us/step - loss: 82.5305 - mae: 6.6381\n",
      "Epoch 19/30\n",
      "323/323 [==============================] - 0s 190us/step - loss: 82.5314 - mae: 6.5187\n",
      "Epoch 20/30\n",
      "323/323 [==============================] - 0s 201us/step - loss: 82.7562 - mae: 6.7728\n",
      "Epoch 21/30\n",
      "323/323 [==============================] - 0s 161us/step - loss: 84.0807 - mae: 6.3919\n",
      "Epoch 22/30\n",
      "323/323 [==============================] - 0s 248us/step - loss: 91.4778 - mae: 7.8274\n",
      "Epoch 23/30\n",
      "323/323 [==============================] - 0s 136us/step - loss: 134.1711 - mae: 8.3084\n",
      "Epoch 24/30\n",
      "323/323 [==============================] - 0s 186us/step - loss: 328.1703 - mae: 16.8690\n",
      "Epoch 25/30\n",
      "323/323 [==============================] - 0s 192us/step - loss: 519.7493 - mae: 20.9211\n",
      "Epoch 26/30\n",
      "323/323 [==============================] - 0s 164us/step - loss: 270.4422 - mae: 15.2024\n",
      "Epoch 27/30\n",
      "323/323 [==============================] - 0s 192us/step - loss: 140.2116 - mae: 8.5936\n",
      "Epoch 28/30\n",
      "323/323 [==============================] - 0s 173us/step - loss: 100.8646 - mae: 8.5129\n",
      "Epoch 29/30\n",
      "323/323 [==============================] - 0s 266us/step - loss: 89.4608 - mae: 6.4136\n",
      "Epoch 30/30\n",
      "323/323 [==============================] - 0s 288us/step - loss: 85.6677 - mae: 7.2653\n",
      "81/81 [==============================] - 0s 5ms/step\n",
      "Epoch 1/30\n",
      "323/323 [==============================] - 2s 5ms/step - loss: 182.5269 - mae: 10.2863\n",
      "Epoch 2/30\n",
      "323/323 [==============================] - 0s 204us/step - loss: 1896.4980 - mae: 42.5339\n",
      "Epoch 3/30\n",
      "323/323 [==============================] - 0s 176us/step - loss: 156.4877 - mae: 9.2015\n",
      "Epoch 4/30\n",
      "323/323 [==============================] - 0s 254us/step - loss: 90.9677 - mae: 7.3099\n",
      "Epoch 5/30\n",
      "323/323 [==============================] - 0s 214us/step - loss: 87.7039 - mae: 6.6245\n",
      "Epoch 6/30\n",
      "323/323 [==============================] - 0s 272us/step - loss: 87.4167 - mae: 6.7366\n",
      "Epoch 7/30\n",
      "323/323 [==============================] - 0s 229us/step - loss: 87.3466 - mae: 6.6819\n",
      "Epoch 8/30\n",
      "323/323 [==============================] - 0s 220us/step - loss: 87.3004 - mae: 6.7016\n",
      "Epoch 9/30\n",
      "323/323 [==============================] - 0s 231us/step - loss: 87.2561 - mae: 6.6871\n",
      "Epoch 10/30\n",
      "323/323 [==============================] - 0s 223us/step - loss: 87.2101 - mae: 6.6919\n",
      "Epoch 11/30\n",
      "323/323 [==============================] - 0s 303us/step - loss: 87.1568 - mae: 6.6838\n",
      "Epoch 12/30\n",
      "323/323 [==============================] - 0s 406us/step - loss: 87.1035 - mae: 6.6852\n",
      "Epoch 13/30\n",
      "323/323 [==============================] - 0s 334us/step - loss: 87.0540 - mae: 6.6785\n",
      "Epoch 14/30\n",
      "323/323 [==============================] - 0s 146us/step - loss: 87.0034 - mae: 6.6799\n",
      "Epoch 15/30\n",
      "323/323 [==============================] - 0s 124us/step - loss: 86.9522 - mae: 6.6725\n",
      "Epoch 16/30\n",
      "323/323 [==============================] - 0s 245us/step - loss: 86.9017 - mae: 6.6754\n",
      "Epoch 17/30\n",
      "323/323 [==============================] - 0s 167us/step - loss: 86.8520 - mae: 6.6649\n",
      "Epoch 18/30\n",
      "323/323 [==============================] - 0s 211us/step - loss: 86.8033 - mae: 6.6737\n",
      "Epoch 19/30\n",
      "323/323 [==============================] - 0s 204us/step - loss: 86.7560 - mae: 6.6523\n",
      "Epoch 20/30\n",
      "323/323 [==============================] - 0s 186us/step - loss: 86.7150 - mae: 6.6832\n",
      "Epoch 21/30\n",
      "323/323 [==============================] - 0s 251us/step - loss: 86.7015 - mae: 6.6196\n",
      "Epoch 22/30\n",
      "323/323 [==============================] - 0s 232us/step - loss: 86.8274 - mae: 6.7647\n",
      "Epoch 23/30\n",
      "323/323 [==============================] - 0s 170us/step - loss: 87.7596 - mae: 6.5224\n",
      "Epoch 24/30\n",
      "323/323 [==============================] - 0s 192us/step - loss: 93.9603 - mae: 7.7099\n",
      "Epoch 25/30\n",
      "323/323 [==============================] - 0s 170us/step - loss: 136.8761 - mae: 8.3779\n",
      "Epoch 26/30\n",
      "323/323 [==============================] - 0s 205us/step - loss: 364.8063 - mae: 17.8349\n",
      "Epoch 27/30\n",
      "323/323 [==============================] - 0s 111us/step - loss: 547.2673 - mae: 21.4716\n",
      "Epoch 28/30\n",
      "323/323 [==============================] - 0s 149us/step - loss: 273.2147 - mae: 15.2697\n",
      "Epoch 29/30\n",
      "323/323 [==============================] - 0s 167us/step - loss: 142.5612 - mae: 8.6165\n",
      "Epoch 30/30\n",
      "323/323 [==============================] - 0s 198us/step - loss: 104.7688 - mae: 8.5886\n",
      "81/81 [==============================] - 0s 5ms/step\n",
      "Epoch 1/30\n",
      "323/323 [==============================] - 2s 5ms/step - loss: 3162.5798 - mae: 55.5393\n",
      "Epoch 2/30\n",
      "323/323 [==============================] - 0s 173us/step - loss: 228.4765 - mae: 13.8923\n",
      "Epoch 3/30\n",
      "323/323 [==============================] - 0s 142us/step - loss: 85.2659 - mae: 7.2871\n",
      "Epoch 4/30\n",
      "323/323 [==============================] - 0s 155us/step - loss: 78.8647 - mae: 6.4502\n",
      "Epoch 5/30\n",
      "323/323 [==============================] - 0s 71us/step - loss: 78.6714 - mae: 6.3791\n",
      "Epoch 6/30\n",
      "323/323 [==============================] - 0s 266us/step - loss: 78.6347 - mae: 6.3696\n",
      "Epoch 7/30\n",
      "323/323 [==============================] - 0s 232us/step - loss: 78.6010 - mae: 6.3670\n",
      "Epoch 8/30\n",
      "323/323 [==============================] - 0s 176us/step - loss: 78.5680 - mae: 6.3649\n",
      "Epoch 9/30\n",
      "323/323 [==============================] - 0s 176us/step - loss: 78.5354 - mae: 6.3629\n",
      "Epoch 10/30\n",
      "323/323 [==============================] - 0s 130us/step - loss: 78.5029 - mae: 6.3609\n",
      "Epoch 11/30\n",
      "323/323 [==============================] - 0s 223us/step - loss: 78.4706 - mae: 6.3588\n",
      "Epoch 12/30\n",
      "323/323 [==============================] - 0s 90us/step - loss: 78.4380 - mae: 6.3568\n",
      "Epoch 13/30\n",
      "323/323 [==============================] - 0s 192us/step - loss: 78.4050 - mae: 6.3548\n",
      "Epoch 14/30\n",
      "323/323 [==============================] - 0s 282us/step - loss: 78.3716 - mae: 6.3528\n",
      "Epoch 15/30\n",
      "323/323 [==============================] - 0s 146us/step - loss: 78.3377 - mae: 6.3507\n",
      "Epoch 16/30\n",
      "323/323 [==============================] - 0s 118us/step - loss: 78.3032 - mae: 6.3486\n",
      "Epoch 17/30\n",
      "323/323 [==============================] - 0s 152us/step - loss: 78.2680 - mae: 6.3465\n",
      "Epoch 18/30\n",
      "323/323 [==============================] - 0s 214us/step - loss: 78.2321 - mae: 6.3443\n",
      "Epoch 19/30\n",
      "323/323 [==============================] - 0s 310us/step - loss: 78.1955 - mae: 6.3421\n",
      "Epoch 20/30\n",
      "323/323 [==============================] - 0s 245us/step - loss: 78.1581 - mae: 6.3399\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/30\n",
      "323/323 [==============================] - 0s 288us/step - loss: 78.1197 - mae: 6.3375\n",
      "Epoch 22/30\n",
      "323/323 [==============================] - 0s 245us/step - loss: 78.0803 - mae: 6.3352\n",
      "Epoch 23/30\n",
      "323/323 [==============================] - 0s 367us/step - loss: 78.0397 - mae: 6.3328\n",
      "Epoch 24/30\n",
      "323/323 [==============================] - 0s 316us/step - loss: 77.9980 - mae: 6.3304\n",
      "Epoch 25/30\n",
      "323/323 [==============================] - 0s 108us/step - loss: 77.9550 - mae: 6.3277\n",
      "Epoch 26/30\n",
      "323/323 [==============================] - 0s 186us/step - loss: 77.9107 - mae: 6.3253\n",
      "Epoch 27/30\n",
      "323/323 [==============================] - 0s 124us/step - loss: 77.8650 - mae: 6.3222\n",
      "Epoch 28/30\n",
      "323/323 [==============================] - 0s 56us/step - loss: 77.8179 - mae: 6.3203\n",
      "Epoch 29/30\n",
      "323/323 [==============================] - 0s 170us/step - loss: 77.7692 - mae: 6.3155\n",
      "Epoch 30/30\n",
      "323/323 [==============================] - 0s 220us/step - loss: 77.7191 - mae: 6.3171\n",
      "81/81 [==============================] - 0s 6ms/step\n",
      "Epoch 1/30\n",
      "323/323 [==============================] - 2s 6ms/step - loss: 2814.5327 - mae: 52.2237\n",
      "Epoch 2/30\n",
      "323/323 [==============================] - 0s 53us/step - loss: 105.5788 - mae: 7.1955\n",
      "Epoch 3/30\n",
      "323/323 [==============================] - 0s 56us/step - loss: 89.2788 - mae: 7.0533\n",
      "Epoch 4/30\n",
      "323/323 [==============================] - 0s 59us/step - loss: 88.6117 - mae: 6.8537\n",
      "Epoch 5/30\n",
      "323/323 [==============================] - 0s 1us/step - loss: 88.1189 - mae: 6.8676\n",
      "Epoch 6/30\n",
      "323/323 [==============================] - 0s 49us/step - loss: 87.8301 - mae: 6.8515\n",
      "Epoch 7/30\n",
      "323/323 [==============================] - 0s 97us/step - loss: 87.7529 - mae: 6.8361\n",
      "Epoch 8/30\n",
      "323/323 [==============================] - 0s 48us/step - loss: 87.6882 - mae: 6.8357\n",
      "Epoch 9/30\n",
      "323/323 [==============================] - 0s 165us/step - loss: 87.6241 - mae: 6.8295\n",
      "Epoch 10/30\n",
      "323/323 [==============================] - 0s 97us/step - loss: 87.5600 - mae: 6.8274\n",
      "Epoch 11/30\n",
      "323/323 [==============================] - 0s 590us/step - loss: 87.4961 - mae: 6.8211\n",
      "Epoch 12/30\n",
      "323/323 [==============================] - 0s 433us/step - loss: 87.4312 - mae: 6.8211\n",
      "Epoch 13/30\n",
      "323/323 [==============================] - 0s 105us/step - loss: 87.3647 - mae: 6.8116\n",
      "Epoch 14/30\n",
      "323/323 [==============================] - 0s 149us/step - loss: 87.2976 - mae: 6.8159\n",
      "Epoch 15/30\n",
      "323/323 [==============================] - 0s 257us/step - loss: 87.2283 - mae: 6.8001\n",
      "Epoch 16/30\n",
      "323/323 [==============================] - 0s 145us/step - loss: 87.1600 - mae: 6.8144\n",
      "Epoch 17/30\n",
      "323/323 [==============================] - 0s 262us/step - loss: 87.0915 - mae: 6.7820\n",
      "Epoch 18/30\n",
      "323/323 [==============================] - 0s 188us/step - loss: 87.0356 - mae: 6.8270\n",
      "Epoch 19/30\n",
      "323/323 [==============================] - 0s 105us/step - loss: 87.0222 - mae: 6.7402\n",
      "Epoch 20/30\n",
      "323/323 [==============================] - 0s 223us/step - loss: 87.2008 - mae: 6.9219\n",
      "Epoch 21/30\n",
      "323/323 [==============================] - 0s 117us/step - loss: 88.2912 - mae: 6.6491\n",
      "Epoch 22/30\n",
      "323/323 [==============================] - 0s 151us/step - loss: 94.4383 - mae: 7.8365\n",
      "Epoch 23/30\n",
      "323/323 [==============================] - 0s 136us/step - loss: 129.1302 - mae: 8.1636\n",
      "Epoch 24/30\n",
      "323/323 [==============================] - 0s 90us/step - loss: 282.9882 - mae: 15.4649\n",
      "Epoch 25/30\n",
      "323/323 [==============================] - 0s 122us/step - loss: 492.0822 - mae: 20.1146\n",
      "Epoch 26/30\n",
      "323/323 [==============================] - 0s 140us/step - loss: 327.9952 - mae: 16.7554\n",
      "Epoch 27/30\n",
      "323/323 [==============================] - 0s 87us/step - loss: 188.1403 - mae: 10.4929\n",
      "Epoch 28/30\n",
      "323/323 [==============================] - 0s 87us/step - loss: 129.2573 - mae: 9.9601\n",
      "Epoch 29/30\n",
      "323/323 [==============================] - 0s 118us/step - loss: 105.1520 - mae: 7.1246\n",
      "Epoch 30/30\n",
      "323/323 [==============================] - 0s 77us/step - loss: 96.4486 - mae: 8.0178\n",
      "81/81 [==============================] - 0s 6ms/step\n",
      "Epoch 1/30\n",
      "324/324 [==============================] - 2s 7ms/step - loss: 1090.0392 - mae: 31.7111\n",
      "Epoch 2/30\n",
      "324/324 [==============================] - 0s 49us/step - loss: 1898.2755 - mae: 42.5575\n",
      "Epoch 3/30\n",
      "324/324 [==============================] - 0s 62us/step - loss: 272.2570 - mae: 13.7605\n",
      "Epoch 4/30\n",
      "324/324 [==============================] - 0s 62us/step - loss: 103.8409 - mae: 8.4976\n",
      "Epoch 5/30\n",
      "324/324 [==============================] - 0s 62us/step - loss: 87.8656 - mae: 6.6698\n",
      "Epoch 6/30\n",
      "324/324 [==============================] - 0s 284us/step - loss: 85.6397 - mae: 6.9048\n",
      "Epoch 7/30\n",
      "324/324 [==============================] - 0s 164us/step - loss: 84.9986 - mae: 6.6633\n",
      "Epoch 8/30\n",
      "324/324 [==============================] - 0s 179us/step - loss: 84.7712 - mae: 6.7743\n",
      "Epoch 9/30\n",
      "324/324 [==============================] - 0s 174us/step - loss: 84.6299 - mae: 6.6763\n",
      "Epoch 10/30\n",
      "324/324 [==============================] - 0s 236us/step - loss: 84.5331 - mae: 6.7481\n",
      "Epoch 11/30\n",
      "324/324 [==============================] - 0s 193us/step - loss: 84.4468 - mae: 6.6689\n",
      "Epoch 12/30\n",
      "324/324 [==============================] - 0s 279us/step - loss: 84.3819 - mae: 6.7468\n",
      "Epoch 13/30\n",
      "324/324 [==============================] - 0s 196us/step - loss: 84.3480 - mae: 6.6473\n",
      "Epoch 14/30\n",
      "324/324 [==============================] - 0s 150us/step - loss: 84.3686 - mae: 6.7811\n",
      "Epoch 15/30\n",
      "324/324 [==============================] - 0s 193us/step - loss: 84.5606 - mae: 6.6025\n",
      "Epoch 16/30\n",
      "324/324 [==============================] - 0s 74us/step - loss: 85.2515 - mae: 6.9541\n",
      "Epoch 17/30\n",
      "324/324 [==============================] - 0s 145us/step - loss: 87.6478 - mae: 6.6120\n",
      "Epoch 18/30\n",
      "324/324 [==============================] - 0s 74us/step - loss: 96.6543 - mae: 8.0521\n",
      "Epoch 19/30\n",
      "324/324 [==============================] - 0s 171us/step - loss: 127.9402 - mae: 8.2738\n",
      "Epoch 20/30\n",
      "324/324 [==============================] - 0s 212us/step - loss: 241.7481 - mae: 14.1562\n",
      "Epoch 21/30\n",
      "324/324 [==============================] - 0s 72us/step - loss: 498.1243 - mae: 20.3459\n",
      "Epoch 22/30\n",
      "324/324 [==============================] - 0s 48us/step - loss: 573.0453 - mae: 22.4828\n",
      "Epoch 23/30\n",
      "324/324 [==============================] - 0s 48us/step - loss: 369.7586 - mae: 16.9098\n",
      "Epoch 24/30\n",
      "324/324 [==============================] - 0s 126us/step - loss: 213.8894 - mae: 13.2324\n",
      "Epoch 25/30\n",
      "324/324 [==============================] - 0s 52us/step - loss: 144.3804 - mae: 8.9453\n",
      "Epoch 26/30\n",
      "324/324 [==============================] - 0s 48us/step - loss: 116.4272 - mae: 9.2645\n",
      "Epoch 27/30\n",
      "324/324 [==============================] - 0s 48us/step - loss: 104.8099 - mae: 7.3292\n",
      "Epoch 28/30\n",
      "324/324 [==============================] - 0s 48us/step - loss: 100.1736 - mae: 8.3189\n",
      "Epoch 29/30\n",
      "324/324 [==============================] - 0s 48us/step - loss: 99.1715 - mae: 7.0758\n",
      "Epoch 30/30\n",
      "324/324 [==============================] - 0s 68us/step - loss: 101.1011 - mae: 8.3861\n",
      "80/80 [==============================] - 1s 7ms/step\n"
     ]
    }
   ],
   "source": [
    "cv_mae = []\n",
    "train_mae = []\n",
    "for train_index, test_index in kfold.split(train_data, train_targets):\n",
    "    model = build_model()\n",
    "    history = model.fit(train_data[train_index], train_targets[train_index], epochs=30, batch_size=2024)\n",
    "    scores = model.evaluate(train_data[test_index], train_targets[test_index])\n",
    "    cv_mae.append(scores[1])\n",
    "    train_mae.append(history.history['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'mae'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7.036622047424316,\n",
       " 6.9151225090026855,\n",
       " 7.3958635330200195,\n",
       " 5.255573749542236,\n",
       " 6.58764123916626]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[110.81847755581725, 8.001017570495605]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_data, test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_19 (Dense)             (None, 64)                896       \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 5,121\n",
      "Trainable params: 5,121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected dense_19_input to have shape (13,) but got array with shape (1,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-306b86b23b1e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1439\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1440\u001b[0m         \u001b[1;31m# Case 2: Symbolic tensors or Numpy array-like.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1441\u001b[1;33m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_standardize_user_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1442\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1443\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    577\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    578\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 579\u001b[1;33m             exception_prefix='input')\n\u001b[0m\u001b[0;32m    580\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    581\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    143\u001b[0m                             \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' but got array with shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 145\u001b[1;33m                             str(data_shape))\n\u001b[0m\u001b[0;32m    146\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected dense_19_input to have shape (13,) but got array with shape (1,)"
     ]
    }
   ],
   "source": [
    "model.predict(test_data[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_targets[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
